<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="GestureHYDRA: Semantic Co-speech Gesture Synthesis via Hybrid Modality Diffusion Transformer and Cascaded-Synchronized Retrieval-Augmented Generation">
  <meta name="keywords" content="Co-speech Gesture, Diffusion Transformer">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>GestureHYDRA: Semantic Co-speech Gesture Synthesis via Hybrid Modality Diffusion Transformer and Cascaded-Synchronized Retrieval-Augmented Generation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/logo.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-3 publication-title">GestureHYDRA: Semantic Co-speech Gesture Synthesis via Hybrid Modality Diffusion Transformer and Cascaded-Synchronized Retrieval-Augmented Generation</h1>
          <!-- <h4 class="subtitle is-5"><em>ICCV 2025 </em> </h4> -->
          <h4 class="subtitle is-5 has-text-weight-semibold" style="font-style: italic;">
            ICCV 2025
          </h4>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://mumuwei.github.io/">Quanwei Yang</a><sup>1*</sup>,</span>
            <span class="author-block">
                <a href="https://hlyyyyy.github.io/">Luying Huang</a><sup>2*</sup>,</span> 
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=2Pedf3EAAAAJ">Kaisiyuan Wang</a><sup>2†</sup>,
            </span>
            <span class="author-block">
              <a href="https://guanjz20.github.io/">Jiazhi Guan</a><sup>2</sup>,</span>
            <span class="author-block">
              <a >Shengyi He</a><sup>2</sup>,</span>
            <span class="author-block">
                <a >Fengluo Li</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://hangz-nju-cuhk.github.io/">Hang Zhou</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="http://home.ustc.edu.cn/~yuly/">Lingyun Yu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a >Yingying Li</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=pnuQ5UsAAAAJ&view_op=list_works&sortby=pubdate">Haocheng Feng</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://faculty.ustc.edu.cn/xiehongtao/zh_CN/index.htm">Hongtao Xie</a><sup>1†</sup>
            </span>
            
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Science and Technology of China,</span>
            <span class="author-block"><sup>2</sup>VIS, Baidu Inc.</span>
          </div>
          <div class="is-size-6">
            <span><sup>*</sup> Equal contribution.</span>
            <span style="margin-left: 1em;"><sup>†</sup> Corresponding authors.</span>
          </div>
          
          
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2507.22731"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2507.22731"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=ISCdBlRgjiM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/mumuwei/Streamer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>
            

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
      <img src="./static/images/pipeline_iccv.png"  width="800px" height="500px" 
        type="application/pdf">
      </img>
      
      <h2 class="subtitle has-text-centered">
      </h2>

  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <source src="./static/videos/steve.mp4" type="video/mp4">
      </div>
    </div>
  </div>
</section> 
    





<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          While increasing attention has been paid to co-speech gesture synthesis, most previous works neglect to investigate hand gestures with explicit and essential semantics.
          In this paper, we study co-speech gesture generation with an emphasis on specific hand gesture activation, which can deliver more instructional information than common body movements.
          To achieve this, we first build a high-quality dataset of 3D human body movements including a set of semantically explicit hand gestures that are commonly used by live streamers.
          Then we present a hybrid-modality gesture generation system GestureHYDRA built upon a hybrid-modality diffusion transformer architecture with novelly designed motion-style injective transformer layers, which enables advanced gesture modeling ability and versatile gesture operations.
          To guarantee these specific hand gestures can be activated, we introduce a cascaded retrieval-augmented generation strategy built upon a semantic gesture repository annotated for each subject and an adaptive audio-gesture synchronization mechanism, which substantially improves semantic gesture activation and production efficiency.
          Quantitative and qualitative experiments demonstrate that our proposed approach achieves superior performance over all the counterparts.
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


    <!-- Re-rendering -->
    <section class="section">
      <div class="container">
        <!-- 居中标题 -->
        <h2 class="title is-3 has-text-centered">Generated Results</h2>

        <!-- 视频简介内容 -->
        <div class="content has-text-justified">
          <p style="color: #003366; font-weight: bold; font-size: 1.25rem;">
            Comparisons on the TalkSHOW Dataset
          </p>
        </div>
        
        <!-- 多个视频横向排列 -->
        <div class="columns is-multiline is-variable is-2">
          <!-- 视频 1 -->
          <div class="column is-one-two">
            <video controls muted preload playsinline width="100%">
              <source src="https://modelscope.cn/datasets/Hlyyyyy/GestureHydra_videos/resolve/master/show02.mp4" type="video/mp4">
            </video>
          </div>
          <!-- 视频 2 -->
          <div class="column is-one-two">
            <video controls muted preload playsinline width="100%">
              <source src="https://modelscope.cn/datasets/Hlyyyyy/GestureHydra_videos/resolve/master/show03.mp4" type="video/mp4">
            </video>
          </div>
          </div>

          <!-- 视频简介内容 Comparisons on the Streamer Dataset -->
          <div class="content has-text-justified">
            <p style="color: #003366; font-weight: bold; font-size: 1.25rem;">
              Comparisons on the Streamer Dataset
            </p>
          </div>

          <!-- 多个视频横向排列，每行2个，共4个 -->
          <div class="columns is-multiline is-variable is-2">
            <!-- 视频 1 -->
            <div class="column is-half">
              <video controls muted preload playsinline width="100%">
                <source src="https://modelscope.cn/datasets/Hlyyyyy/GestureHydra_videos/resolve/master/streamer01.mp4" type="video/mp4">
              </video>
            </div>
            <!-- 视频 2 -->
            <div class="column is-half">
              <video controls muted preload playsinline width="100%">
                <source src="https://modelscope.cn/datasets/Hlyyyyy/GestureHydra_videos/resolve/master/streamer02.mp4" type="video/mp4">
              </video>
            </div>
            <!-- 视频 3 -->
            <div class="column is-half">
              <video controls muted preload playsinline width="100%">
                <source src="https://modelscope.cn/datasets/Hlyyyyy/GestureHydra_videos/resolve/master/streamer03.mp4" type="video/mp4">
              </video>
            </div>
            <!-- 视频 4 -->
            <div class="column is-half">
              <video controls muted preload playsinline width="100%">
                <source src="https://modelscope.cn/datasets/Hlyyyyy/GestureHydra_videos/resolve/master/streamer04.mp4" type="video/mp4">
              </video>
            </div>
          </div>

        <!-- 视频简介内容 -->
        <div class="content has-text-justified">
          <p style="color: #003366; font-weight: bold; font-size: 1.25rem;">
            Adaptive Key Frame Injection Results
          </p>
        </div>

        <!-- 多个视频横向排列 -->
        <div class="columns is-multiline is-variable is-2">
          <!-- 视频 1 -->
          <div class="column is-one-two">
            <video controls muted preload playsinline width="100%">
              <source src="https://modelscope.cn/datasets/Hlyyyyy/GestureHydra_videos/resolve/master/injection01.mp4" type="video/mp4">
            </video>
          </div>
          <!-- 视频 2 -->
          <div class="column is-one-two">
            <video controls muted preload playsinline width="100%">
              <source src="https://modelscope.cn/datasets/Hlyyyyy/GestureHydra_videos/resolve/master/injection02.mp4" type="video/mp4">
            </video>
          </div>
          </div>
        
          <!-- 视频简介内容 -->
          <div class="content has-text-justified">
            <p style="color: #003366; font-weight: bold; font-size: 1.25rem;">
              Gesture Editing Results
            </p>
          </div>
  
          <!-- 多个视频横向排列 -->
          <div class="columns is-multiline is-variable is-2">
            <!-- 视频 1 -->
            <div class="column is-one-two">
              <video controls muted preload playsinline width="100%">
                <source src="https://modelscope.cn/datasets/Hlyyyyy/GestureHydra_videos/resolve/master/head2tail.mp4" type="video/mp4">
              </video>
            </div>
            <!-- 视频 2 -->
            <div class="column is-one-two">
              <video controls muted preload playsinline width="100%">
                <source src="https://modelscope.cn/datasets/Hlyyyyy/GestureHydra_videos/resolve/master/replace01.mp4" type="video/mp4">
              </video>
            </div>
            </div>
            
          
          <!-- 视频简介内容 -->
          <div class="content has-text-justified">
            <p style="color: #003366; font-weight: bold; font-size: 1.25rem;">
              Video Generation based on Synthetized Gestures
            </p>
          </div>
  
          <div class="columns is-multiline is-variable is-2">
            <!-- 视频 1 -->
            <div class="column is-one has-text-centered">
              <video controls muted preload playsinline width="80%" style="display: inline-block;">
                <source src="https://modelscope.cn/datasets/Hlyyyyy/GestureHydra_videos/resolve/master/video_gen.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        
          
        </div>
      </div>
    </section>
  <!--/ Re-rendering -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction Video</h2>
        <!-- <div class="publication-video"> -->
          <!-- <video poster="" id="paper-video" autoplay controls muted loop playsinline height="100%"> -->
          <!-- <video width="800" height="600" controls>
            <source src="https://www.youtube.com/watch?v=jWvAglDGWxA&t=1s" type="video/mp4">
          </video> -->
          <iframe width="800" height="480"
           src="https://www.youtube.com/embed/0IRep9Bhu_k?si=rZoRlPGfKgVmoXDD" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
          </iframe>
          <!-- </video> -->
        <!-- </div> -->
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<!-- <video width="320" height="240" controls>
  <source src="videos/movie.mp4" type="video/new_sup_final_crf20.mp4">
  Your browser does not support the video tag.
</video> -->


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{yang2025GestureHYDRA,
  author    = {Quanwei Yang, Luying Huang, Kaisiyuan Wang, Jiazhi Guan, Shengyi He, Fengguo Li, Lingyun Yu, Yingying Li, Haocheng Feng, Hang Zhou, Hongtao Xie.},
  title     = {GestureHYDRA: Semantic Co-speech Gesture Synthesis via Hybrid Modality Diffusion Transformer and Cascaded-Synchronized Retrieval-Augmented Generation},
  booktitle = {ICCV},
  year      = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            <!-- This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website. -->
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
